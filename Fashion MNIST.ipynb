{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST Classification using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we will take the training set of 60000 images of Fashion MNIST dataset and:\n",
    "#### 1. Load Dataset\n",
    "#### 2. Train a baseline model\n",
    "#### 3. Hyperparameter tuning\n",
    "#### 4. Train the refined model\n",
    "#### 5. Evaluate the model on test set of 10000 images of Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset\n",
    "#### We import the required packages and load the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True) #Already on by default, we write to remember this point\n",
    "\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore',category=FutureWarning)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model would predict probability of an image being in all the 10 classes. Using the below function, we get the max probability(hence the prediction by our model) and compare it with the true value to gain the total number of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we define our model. We would be building 2 Convolution Layers following with 2 Fully Connected Layers and then an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6,out_channels = 12,kernel_size = 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4,out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        \n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        t = t\n",
    "        \n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t,kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t,kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = t.reshape(-1,12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Total Correct: 28561 Loss: 93.50459921360016\n",
      "Epoch: 1 Total Correct: 41330 Loss: 48.831675827503204\n",
      "Epoch: 2 Total Correct: 44051 Loss: 41.601802110672\n",
      "Epoch: 3 Total Correct: 45336 Loss: 38.08242577314377\n",
      "Epoch: 4 Total Correct: 46369 Loss: 35.712429225444794\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1000)\n",
    "optimizer = optim.Adam(network.parameters(), lr= 0.001)\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images,labels = batch\n",
    "\n",
    "        preds = network(images)#Pass Batch\n",
    "        loss = F.cross_entropy(preds,labels)#Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad() #Pytorch accumulates gradients i.e. it adds. We want new gradient and so we zero out everytime\n",
    "\n",
    "        loss.backward()#Calculate Gradient\n",
    "        optimizer.step()#Update Weight\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "        total_correct = total_correct + get_num_correct(preds,labels)\n",
    "\n",
    "    print('Epoch:',epoch,\"Total Correct:\",total_correct,\"Loss:\",total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7728166666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct/len(train_set) #Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we define a function to make the predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_preds(model,loader):\n",
    "    all_preds = torch.tensor([])#Initialize empty tensor\n",
    "    \n",
    "    for batch in loader:#read data batch wise from loader, predict batchwise and concatenate results.\n",
    "        images,labels = batch\n",
    "        \n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat((all_preds,preds),dim=0) #Hence get all predictions for our test set\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_loader = torch.utils.data.DataLoader(test_set,batch_size = 1000)\n",
    "test_preds = get_all_preds(network,prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct: 7736\n",
      "Accuracy: 0.7736\n"
     ]
    }
   ],
   "source": [
    "preds_correct = get_num_correct(test_preds,test_set.targets)\n",
    "\n",
    "print(\"Total Correct:\",preds_correct)\n",
    "print(\"Accuracy:\",preds_correct/len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, we got a training accuracy of 77.28 % and test accuracy of 77.36 %. Let us look at finding optimal parameters to find a model with better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run',params.keys())#Making Run(keys)\n",
    "        runs = []\n",
    "        \n",
    "        for v in product(*params.values()):#Appending values to keys using Cartesian Product\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    def __init__(self):#Definding attributes to keep track of data across epochs and runs\n",
    "        \n",
    "        #Some attributes for epochs\n",
    "        self.epoch_count=0#Number of epochs\n",
    "        self.epoch_loss = 0#Loss for epoch\n",
    "        self.epoch_num_correct = 0 #Correct number of predictions\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        #Some attributes for runs\n",
    "        self.run_params = None#Value from run builder\n",
    "        self.run_count = 0\n",
    "        self.run_data = []#Keep track of parameter values\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None#Save network for the run\n",
    "        self.loader = None#Save dataloader for the run\n",
    "        self.tb = None#Save data to tensorboard\n",
    "        \n",
    "    def begin_run(self,run,network,loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment = f'-{run}')\n",
    "        \n",
    "        images,labels = next(iter(loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images',grid)\n",
    "        self.tb.add_graph(network,images)\n",
    "\n",
    "    \n",
    "    def end_run(self):\n",
    "        self.tb.close()#Close tensorboard handle\n",
    "        self.epoch_count = 0#Set epoch_count to 0 to be ready for next run\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count +=1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0 \n",
    "        \n",
    "    def end_epoch(self):\n",
    "        #When ending epoch we need to do some summary calculations\n",
    "        \n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss',loss,self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy',accuracy,self.epoch_count)\n",
    "        \n",
    "        for name,param in network.named_parameters():#Give the histogram for all the layers.\n",
    "            self.tb.add_histogram(name,param,self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad',param.grad,self.epoch_count)\n",
    "            \n",
    "        ## Now creating a summary table outside of Tensorboard analysis\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count\n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['accuracy'] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        \n",
    "        for k,v in self.run_params._asdict().items():\n",
    "            results[k] = v#Adding Parameters keys and values inside the result dictionary\n",
    "            \n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data,orient='columns')\n",
    "        \n",
    "        clear_output(wait=True)#For Jupyter notebook to clear whatever output is\n",
    "        display(df)#Display the new DF\n",
    "        \n",
    "    def track_loss(self,loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "        \n",
    "    def track_num_correct(self,preds,labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self,preds,labels):#_before name suggests reader that this is being used within the class\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551635</td>\n",
       "      <td>0.791583</td>\n",
       "      <td>11.545965</td>\n",
       "      <td>11.688490</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.387204</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>11.735774</td>\n",
       "      <td>23.566050</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.357973</td>\n",
       "      <td>0.867367</td>\n",
       "      <td>11.920362</td>\n",
       "      <td>35.619498</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340564</td>\n",
       "      <td>0.874717</td>\n",
       "      <td>11.734072</td>\n",
       "      <td>47.495862</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.331860</td>\n",
       "      <td>0.877817</td>\n",
       "      <td>11.608809</td>\n",
       "      <td>59.235632</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936382</td>\n",
       "      <td>0.646050</td>\n",
       "      <td>9.430365</td>\n",
       "      <td>10.027687</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.506092</td>\n",
       "      <td>0.807900</td>\n",
       "      <td>9.550581</td>\n",
       "      <td>19.729244</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.418793</td>\n",
       "      <td>0.845450</td>\n",
       "      <td>9.495852</td>\n",
       "      <td>29.345749</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.365571</td>\n",
       "      <td>0.864900</td>\n",
       "      <td>9.697335</td>\n",
       "      <td>39.188346</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.338059</td>\n",
       "      <td>0.874367</td>\n",
       "      <td>10.102572</td>\n",
       "      <td>49.434483</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.146860</td>\n",
       "      <td>0.212450</td>\n",
       "      <td>9.844059</td>\n",
       "      <td>15.561243</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.306828</td>\n",
       "      <td>0.520217</td>\n",
       "      <td>9.876935</td>\n",
       "      <td>25.557076</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.960363</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>9.931699</td>\n",
       "      <td>35.612077</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.809149</td>\n",
       "      <td>0.691850</td>\n",
       "      <td>9.959538</td>\n",
       "      <td>45.694964</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.725677</td>\n",
       "      <td>0.715583</td>\n",
       "      <td>10.033668</td>\n",
       "      <td>55.847015</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748986</td>\n",
       "      <td>0.717083</td>\n",
       "      <td>11.978418</td>\n",
       "      <td>12.097678</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.501753</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>12.886705</td>\n",
       "      <td>25.122152</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.435887</td>\n",
       "      <td>0.841650</td>\n",
       "      <td>15.607262</td>\n",
       "      <td>40.895755</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394689</td>\n",
       "      <td>0.855583</td>\n",
       "      <td>12.972341</td>\n",
       "      <td>54.009705</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.365790</td>\n",
       "      <td>0.864483</td>\n",
       "      <td>12.220873</td>\n",
       "      <td>66.386046</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.669623</td>\n",
       "      <td>0.434883</td>\n",
       "      <td>9.942212</td>\n",
       "      <td>10.614286</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.701517</td>\n",
       "      <td>9.853988</td>\n",
       "      <td>20.614659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.676138</td>\n",
       "      <td>0.739133</td>\n",
       "      <td>10.648807</td>\n",
       "      <td>31.410906</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.609657</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>10.323086</td>\n",
       "      <td>41.887077</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.567523</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>10.086594</td>\n",
       "      <td>52.108030</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.297928</td>\n",
       "      <td>0.100117</td>\n",
       "      <td>10.417557</td>\n",
       "      <td>16.320581</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.261972</td>\n",
       "      <td>0.292783</td>\n",
       "      <td>10.077472</td>\n",
       "      <td>26.523413</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.154267</td>\n",
       "      <td>0.428833</td>\n",
       "      <td>10.029636</td>\n",
       "      <td>36.696906</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.893375</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>10.109613</td>\n",
       "      <td>46.941145</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.488068</td>\n",
       "      <td>0.529233</td>\n",
       "      <td>10.471509</td>\n",
       "      <td>57.563480</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration     lr  \\\n",
       "0     1      1  0.551635  0.791583       11.545965     11.688490  0.010   \n",
       "1     1      2  0.387204  0.856317       11.735774     23.566050  0.010   \n",
       "2     1      3  0.357973  0.867367       11.920362     35.619498  0.010   \n",
       "3     1      4  0.340564  0.874717       11.734072     47.495862  0.010   \n",
       "4     1      5  0.331860  0.877817       11.608809     59.235632  0.010   \n",
       "5     2      1  0.936382  0.646050        9.430365     10.027687  0.010   \n",
       "6     2      2  0.506092  0.807900        9.550581     19.729244  0.010   \n",
       "7     2      3  0.418793  0.845450        9.495852     29.345749  0.010   \n",
       "8     2      4  0.365571  0.864900        9.697335     39.188346  0.010   \n",
       "9     2      5  0.338059  0.874367       10.102572     49.434483  0.010   \n",
       "10    3      1  2.146860  0.212450        9.844059     15.561243  0.010   \n",
       "11    3      2  1.306828  0.520217        9.876935     25.557076  0.010   \n",
       "12    3      3  0.960363  0.625850        9.931699     35.612077  0.010   \n",
       "13    3      4  0.809149  0.691850        9.959538     45.694964  0.010   \n",
       "14    3      5  0.725677  0.715583       10.033668     55.847015  0.010   \n",
       "15    4      1  0.748986  0.717083       11.978418     12.097678  0.001   \n",
       "16    4      2  0.501753  0.813600       12.886705     25.122152  0.001   \n",
       "17    4      3  0.435887  0.841650       15.607262     40.895755  0.001   \n",
       "18    4      4  0.394689  0.855583       12.972341     54.009705  0.001   \n",
       "19    4      5  0.365790  0.864483       12.220873     66.386046  0.001   \n",
       "20    5      1  1.669623  0.434883        9.942212     10.614286  0.001   \n",
       "21    5      2  0.792388  0.701517        9.853988     20.614659  0.001   \n",
       "22    5      3  0.676138  0.739133       10.648807     31.410906  0.001   \n",
       "23    5      4  0.609657  0.761667       10.323086     41.887077  0.001   \n",
       "24    5      5  0.567523  0.778000       10.086594     52.108030  0.001   \n",
       "25    6      1  2.297928  0.100117       10.417557     16.320581  0.001   \n",
       "26    6      2  2.261972  0.292783       10.077472     26.523413  0.001   \n",
       "27    6      3  2.154267  0.428833       10.029636     36.696906  0.001   \n",
       "28    6      4  1.893375  0.482000       10.109613     46.941145  0.001   \n",
       "29    6      5  1.488068  0.529233       10.471509     57.563480  0.001   \n",
       "\n",
       "    batch_size  \n",
       "0          100  \n",
       "1          100  \n",
       "2          100  \n",
       "3          100  \n",
       "4          100  \n",
       "5         1000  \n",
       "6         1000  \n",
       "7         1000  \n",
       "8         1000  \n",
       "9         1000  \n",
       "10       10000  \n",
       "11       10000  \n",
       "12       10000  \n",
       "13       10000  \n",
       "14       10000  \n",
       "15         100  \n",
       "16         100  \n",
       "17         100  \n",
       "18         100  \n",
       "19         100  \n",
       "20        1000  \n",
       "21        1000  \n",
       "22        1000  \n",
       "23        1000  \n",
       "24        1000  \n",
       "25       10000  \n",
       "26       10000  \n",
       "27       10000  \n",
       "28       10000  \n",
       "29       10000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "lr = [0.01,0.001],\n",
    "batch_size=[100,1000,10000]\n",
    ")\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    network = Network()\n",
    "    loader = torch.utils.data.DataLoader(train_set,batch_size=run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr= run.lr)\n",
    "\n",
    "    m.begin_run(run,network,loader)\n",
    "       \n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        for batch in loader:\n",
    "            images,labels = batch\n",
    "\n",
    "            preds = network(images)#Pass Batch\n",
    "            loss = F.cross_entropy(preds,labels)#Calculate Loss\n",
    "\n",
    "            optimizer.zero_grad() #Pytorch accumulates gradients i.e. it adds. We want new gradient and so we zero out everytime\n",
    "\n",
    "            loss.backward()#Calculate Gradient\n",
    "            optimizer.step()#Update Weight\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds,labels)\n",
    "        \n",
    "        m.end_epoch()\n",
    "    m.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best accuracy is obtained using batch size of 100 and learning rate of 0.01. We train the model for 5 epochs and print the total loss and correct classified samples after each epoch is completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the refined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Total Correct: 46852 Loss: 345.1322228163481\n",
      "Epoch: 1 Total Correct: 51484 Loss: 229.37994062900543\n",
      "Epoch: 2 Total Correct: 52156 Loss: 212.39699675142765\n",
      "Epoch: 3 Total Correct: 52392 Loss: 203.60295145213604\n",
      "Epoch: 4 Total Correct: 52737 Loss: 197.2160417586565\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=100)\n",
    "optimizer = optim.Adam(network.parameters(), lr= 0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images,labels = batch\n",
    "\n",
    "        preds = network(images)#Pass Batch\n",
    "        loss = F.cross_entropy(preds,labels)#Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad() #Pytorch accumulates gradients i.e. it adds. We want new gradient and so we zero out everytime\n",
    "\n",
    "        loss.backward()#Calculate Gradient\n",
    "        optimizer.step()#Update Weight\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "        total_correct = total_correct + get_num_correct(preds,labels)\n",
    "\n",
    "    print('Epoch:',epoch,\"Total Correct:\",total_correct,\"Loss:\",total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87895"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct/len(train_set) #Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_loader = torch.utils.data.DataLoader(test_set,batch_size = 100)\n",
    "test_preds = get_all_preds(network,prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct: 8615\n",
      "Accuracy: 0.8615\n"
     ]
    }
   ],
   "source": [
    "preds_correct = get_num_correct(test_preds,test_set.targets)\n",
    "\n",
    "print(\"Total Correct:\",preds_correct)\n",
    "print(\"Accuracy:\",preds_correct/len(test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
